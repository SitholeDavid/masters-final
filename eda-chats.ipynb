{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyworld inflect tgt einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-07T07:11:19.998449Z","iopub.execute_input":"2023-08-07T07:11:19.998831Z","iopub.status.idle":"2023-08-07T07:12:06.925787Z","shell.execute_reply.started":"2023-08-07T07:11:19.998801Z","shell.execute_reply":"2023-08-07T07:12:06.924608Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Collecting pyworld\n  Downloading pyworld-0.3.4.tar.gz (251 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting inflect\n  Downloading inflect-7.0.0-py3-none-any.whl (34 kB)\nCollecting tgt\n  Downloading tgt-1.4.4.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyworld) (1.23.5)\nRequirement already satisfied: cython>=0.24 in /opt/conda/lib/python3.10/site-packages (from pyworld) (0.29.34)\nRequirement already satisfied: pydantic>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from inflect) (1.10.7)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from inflect) (4.5.0)\nBuilding wheels for collected packages: pyworld, tgt\n  Building wheel for pyworld (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=202814 sha256=54b6e26e582a61a324624d8227ab91d4a326f99d66f12329396e3bbfdf354c6c\n  Stored in directory: /root/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\n  Building wheel for tgt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tgt: filename=tgt-1.4.4-py3-none-any.whl size=28929 sha256=532ad1c6265875ce5845b4ef62b943013e501f774b214e1327c0d569021660ba\n  Stored in directory: /root/.cache/pip/wheels/09/e6/aa/821531faeb4e05a65d1c763570e90791467cf0c3f1622dc7e2\nSuccessfully built pyworld tgt\nInstalling collected packages: tgt, pyworld, einops, inflect\nSuccessfully installed einops-0.6.1 inflect-7.0.0 pyworld-0.3.4 tgt-1.4.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"## Standard libraries\nimport os\nimport numpy as np\nimport pandas as pd \nimport random\nimport math\nimport json\nfrom functools import partial\nfrom PIL import Image\nimport wandb\nfrom einops import rearrange, reduce, repeat\nfrom einops.layers.torch import Rearrange\n\n## tqdm for loading bars\nfrom tqdm.notebook import tqdm\n\n## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# PyTorch Lightning\ntry:\n    import pytorch_lightning as pl\nexcept ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n    !pip install --quiet pytorch-lightning>=1.4\n    import pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n\n# Setting the seed\npl.seed_everything(42)\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\nfrom pytorch_lightning.loggers import WandbLogger\nwandb_api_key = '430e8c7ef92cf79a3d7c3d02e3d961257153181f'\nos.environ[\"WANDB_API_KEY\"] = wandb_api_key\n\nimport sys; sys.path.insert(0, '/..')\nos.chdir(os.path.join(os.getcwd(), 'masters-final'))\n\n\nfrom text import _clean_text\nfrom text import _symbol_to_id\nfrom audio.tools import inv_mel_spec\nfrom audio.stft import TacotronSTFT\nfrom collections import OrderedDict","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:12:35.542766Z","iopub.execute_input":"2023-08-07T07:12:35.543728Z","iopub.status.idle":"2023-08-07T07:12:55.736727Z","shell.execute_reply.started":"2023-08-07T07:12:35.543679Z","shell.execute_reply":"2023-08-07T07:12:55.735677Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"# import os\n# os.listdir('./masters-final/text')","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:11:03.163498Z","iopub.execute_input":"2023-08-07T07:11:03.163895Z","iopub.status.idle":"2023-08-07T07:11:03.172163Z","shell.execute_reply.started":"2023-08-07T07:11:03.163858Z","shell.execute_reply":"2023-08-07T07:11:03.171208Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['ipa.py',\n 'pinyin.py',\n 'symbols.py',\n 'cmudict.py',\n 'cleaners.py',\n 'numbers.py',\n '__init__.py']"},"metadata":{}}]},{"cell_type":"code","source":"# # Run the following if it's the first time running in this kernel\n#!git clone https://github.com/SitholeDavid/masters-final\n!git pull","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:10:02.291306Z","iopub.execute_input":"2023-08-07T07:10:02.291674Z","iopub.status.idle":"2023-08-07T07:10:21.051683Z","shell.execute_reply.started":"2023-08-07T07:10:02.291645Z","shell.execute_reply":"2023-08-07T07:10:21.050543Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Cloning into 'masters-final'...\nremote: Enumerating objects: 24849, done.\u001b[K\nremote: Counting objects: 100% (24200/24200), done.\u001b[K\nremote: Compressing objects: 100% (174/174), done.\u001b[K\nremote: Total 24849 (delta 24064), reused 24142 (delta 24022), pack-reused 649\u001b[K\nReceiving objects: 100% (24849/24849), 332.24 MiB | 30.88 MiB/s, done.\nResolving deltas: 100% (24225/24225), done.\nUpdating files: 100% (24202/24202), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import librosa.display\n# mel_spec = torch.from_numpy(np.load('./preprocessed_data/LJSpeech/mel/LJSpeech-mel-LJ048-0114.npy'))\n# # mel_spec = torch.from_numpy(np.load('/kaggle/working/masters-final/preprocessed_data/SpanishSingleSpeaker/mel/SpanishSingleSpeaker-mel-19demarzo_0022.npy'))\n# librosa.display.specshow(mel_spec.T.numpy())\n# stft = TacotronSTFT(filter_length=1024, hop_length=256, win_length=1024, n_mel_channels=80, sampling_rate=22050, mel_fmin=0, mel_fmax=8000)\n# inv_mel_spec(mel_spec.T, 'file.wav', stft)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T05:22:13.663096Z","iopub.execute_input":"2023-08-07T05:22:13.663518Z","iopub.status.idle":"2023-08-07T05:22:13.668958Z","shell.execute_reply.started":"2023-08-07T05:22:13.663465Z","shell.execute_reply":"2023-08-07T05:22:13.667782Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Spanish Dataset","metadata":{}},{"cell_type":"code","source":"# !python3 prepare_align.py config/SpanishSingleSpeaker/preprocess.yaml","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:13:24.639657Z","iopub.execute_input":"2023-08-07T07:13:24.640410Z","iopub.status.idle":"2023-08-07T07:22:04.345578Z","shell.execute_reply.started":"2023-08-07T07:13:24.640377Z","shell.execute_reply":"2023-08-07T07:22:04.344317Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"100%|█████████████████████████████████████| 11111/11111 [08:37<00:00, 21.48it/s]\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# !python3 preprocess.py config/SpanishSingleSpeaker/preprocess.yaml","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:22:10.295820Z","iopub.execute_input":"2023-08-07T07:22:10.296911Z","iopub.status.idle":"2023-08-07T07:42:30.364760Z","shell.execute_reply.started":"2023-08-07T07:22:10.296862Z","shell.execute_reply":"2023-08-07T07:42:30.363510Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Processing Data ...\n100%|███████████████████████████████████████████| 1/1 [19:59<00:00, 1199.53s/it]\nComputing statistic quantities ...\nTotal time: 17.2391490047871 hours\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Dataset and Loaders","metadata":{}},{"cell_type":"code","source":"!python3 prepare_align.py config/LJSpeech/preprocess.yaml","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:45:05.380976Z","iopub.execute_input":"2023-08-07T07:45:05.382161Z","iopub.status.idle":"2023-08-07T07:53:43.838604Z","shell.execute_reply.started":"2023-08-07T07:45:05.382119Z","shell.execute_reply":"2023-08-07T07:53:43.835119Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"13100it [08:36, 25.39it/s]\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!python3 preprocess.py config/LJSpeech/preprocess.yaml","metadata":{"execution":{"iopub.status.busy":"2023-08-07T07:53:52.089763Z","iopub.execute_input":"2023-08-07T07:53:52.090209Z","iopub.status.idle":"2023-08-07T08:16:17.021597Z","shell.execute_reply.started":"2023-08-07T07:53:52.090172Z","shell.execute_reply":"2023-08-07T08:16:17.020044Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Processing Data ...\n100%|███████████████████████████████████████████| 1/1 [21:56<00:00, 1316.25s/it]\nComputing statistic quantities ...\nTotal time: 23.62337556059461 hours\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# class SpanishDataset(Dataset):\n#     def __init__(self,  input_dir, input_file, max_src_len, max_trg_len):\n#         self.input_dir = input_dir\n#         self.max_src_len = max_src_len\n#         self.max_trg_len = max_trg_len\n        \n#         files = pd.read_csv(os.path.join(input_dir, input_file), sep='|', header=None)\n#         files.columns = ['file', 'speaker', 'phones', 'text'] \n        \n#         # only consider valid phoneme sequences\n#         for index, row in tqdm(files.iterrows(), total=len(files)):\n#             if not all(symbol in _symbol_to_id for symbol in self._process_phones(row['phones'])):\n#                 files.drop(index, inplace=True)\n\n#         self.file_names = files\n\n#     def _process_phones(self, phones):\n#         phones = phones.replace('{', '').replace('}', '').strip().split(' ')\n#         mapped_phones = [f'@{phone}' for phone in phones]\n#         return mapped_phones\n        \n#     def __len__(self):\n#         return len(self.file_names)\n\n#     def __getitem__(self, idx):\n#         file_name = self.file_names.iloc[idx]['file']\n        \n#         mel = np.load(os.path.join(self.input_dir, 'mel', f'SpanishSingleSpeaker-mel-{file_name}.npy'))\n#         duration = np.load(os.path.join(self.input_dir, 'duration', f'SpanishSingleSpeaker-duration-{file_name}.npy'))\n#         energy = np.load(os.path.join(self.input_dir, 'energy', f'SpanishSingleSpeaker-energy-{file_name}.npy'))\n#         pitch = np.load(os.path.join(self.input_dir, 'pitch', f'SpanishSingleSpeaker-pitch-{file_name}.npy'))\n#         phones = self._process_phones(self.file_names.iloc[idx]['phones'])\n        \n#         phone_mapping = torch.tensor([ _symbol_to_id[symbol] for symbol in phones ])\n\n#         src_len = torch.tensor(len(phones))\n#         trg_len = torch.tensor(mel.shape[0])\n\n#         phoneme_pad_length = self.max_src_len - src_len\n#         mel_pad_length = self.max_trg_len - trg_len\n        \n#         phone_mapping = F.pad(phone_mapping, (0, phoneme_pad_length), mode='constant', value=0)\n#         duration = F.pad( torch.tensor(duration), (0, phoneme_pad_length), mode='constant', value=0)\n#         energy = F.pad( torch.tensor(energy), (0, phoneme_pad_length), mode='constant', value=0)\n#         pitch = F.pad( torch.tensor(pitch), (0, phoneme_pad_length), mode='constant', value=0)\n#         mel = F.pad(torch.tensor(mel), (0, 0, 0, mel_pad_length), mode='constant', value=0)\n#         return  phone_mapping, src_len, mel, trg_len, duration, energy, pitch\n    \n# train_dataset = SpanishDataset('./preprocessed_data/SpanishSingleSpeaker', 'train.txt', max_src_len=200, max_trg_len=1000)\n# val_dataset = SpanishDataset('./preprocessed_data/SpanishSingleSpeaker', 'val.txt', max_src_len=200, max_trg_len=1000)\n\n# # set shuffle to false since we already shuffle when the data is split into train/test\n# train_loader = DataLoader(train_dataset, shuffle=False, batch_size=4, pin_memory=True)\n# val_loader = DataLoader(val_dataset, shuffle=False, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:52:43.841494Z","iopub.execute_input":"2023-08-03T16:52:43.842272Z","iopub.status.idle":"2023-08-03T16:52:45.340326Z","shell.execute_reply.started":"2023-08-03T16:52:43.842236Z","shell.execute_reply":"2023-08-03T16:52:45.339481Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10437 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88128a07ad4042ffbb6a449d87516707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/512 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bc6d0e52eee42a195f1cb79880835ef"}},"metadata":{}}]},{"cell_type":"code","source":"class LJSpeechDataset(Dataset):\n    def __init__(self,  input_dir, input_file, max_src_len, max_trg_len):\n        self.input_dir = input_dir\n        self.max_src_len = max_src_len\n        self.max_trg_len = max_trg_len\n        \n        files = pd.read_csv(os.path.join(input_dir, input_file), sep='|', header=None)\n        files.columns = ['file', 'speaker', 'phones', 'text'] \n        \n        # only consider valid phoneme sequences\n        for index, row in tqdm(files.iterrows(), total=len(files)):\n            if not all(symbol in _symbol_to_id for symbol in self._process_phones(row['phones'])):\n                files.drop(index, inplace=True)\n\n        self.file_names = files\n\n    def _process_phones(self, phones):\n        phones = phones.replace('{', '').replace('}', '').strip().split(' ')\n        mapped_phones = [f'@{phone}' if str.isalnum(phone) else phone for phone in phones]\n        return mapped_phones\n        \n    def __len__(self):\n        return len(self.file_names)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names.iloc[idx]['file']\n        \n        mel = np.load(os.path.join(self.input_dir, 'mel', f'LJSpeech-mel-{file_name}.npy'))\n        duration = np.load(os.path.join(self.input_dir, 'duration', f'LJSpeech-duration-{file_name}.npy'))\n        energy = np.load(os.path.join(self.input_dir, 'energy', f'LJSpeech-energy-{file_name}.npy'))\n        pitch = np.load(os.path.join(self.input_dir, 'pitch', f'LJSpeech-pitch-{file_name}.npy'))\n        phones = self._process_phones(self.file_names.iloc[idx]['phones'])\n        \n        phone_mapping = torch.tensor([ _symbol_to_id[symbol] for symbol in phones ])\n\n        src_len = torch.tensor(len(phones))\n        trg_len = torch.tensor(mel.shape[0])\n\n        phoneme_pad_length = self.max_src_len - src_len\n        mel_pad_length = self.max_trg_len - trg_len\n        \n        phone_mapping = F.pad(phone_mapping, (0, phoneme_pad_length), mode='constant', value=0)\n        duration = F.pad( torch.tensor(duration), (0, phoneme_pad_length), mode='constant', value=0)\n        energy = F.pad( torch.tensor(energy), (0, phoneme_pad_length), mode='constant', value=0)\n        pitch = F.pad( torch.tensor(pitch), (0, phoneme_pad_length), mode='constant', value=0)\n        mel = F.pad(torch.tensor(mel), (0, 0, 0, mel_pad_length), mode='constant', value=0)\n        return  phone_mapping, src_len, mel, trg_len, duration, energy, pitch\n    \ntrain_dataset = LJSpeechDataset('./preprocessed_data/LJSpeech', 'train.txt', max_src_len=200, max_trg_len=1000)\nval_dataset = LJSpeechDataset('./preprocessed_data/LJSpeech', 'val.txt', max_src_len=200, max_trg_len=1000)\n\n# set shuffle to false since we already shuffle when the data is split into train/test\ntrain_loader = DataLoader(train_dataset, shuffle=False, batch_size=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, shuffle=False, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:16:38.727093Z","iopub.execute_input":"2023-08-07T08:16:38.728435Z","iopub.status.idle":"2023-08-07T08:16:40.819890Z","shell.execute_reply.started":"2023-08-07T08:16:38.728380Z","shell.execute_reply":"2023-08-07T08:16:40.818646Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12273 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de3715e026844515a4558a5d7e5c6392"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/454 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e933452067b4ad8a18e0847eedacb02"}},"metadata":{}}]},{"cell_type":"markdown","source":"#### Model Layers","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, max_len):\n        \"\"\"\n        Inputs\n            d_model - Hidden dimensionality of the input.\n            max_len - Maximum length of a sequence to expect.\n        \"\"\"\n        super().__init__()\n\n        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n        # Used for tensors that need to be on the same device as the module.\n        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:16:48.689982Z","iopub.execute_input":"2023-08-07T08:16:48.690359Z","iopub.status.idle":"2023-08-07T08:16:48.699455Z","shell.execute_reply.started":"2023-08-07T08:16:48.690325Z","shell.execute_reply":"2023-08-07T08:16:48.698201Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"stft = TacotronSTFT(filter_length=1024, hop_length=256, win_length=1024, n_mel_channels=80, sampling_rate=22050, mel_fmin=0, mel_fmax=8000)\n#inv_mel_spec(mel_spec.T, 'file.wav', stft)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:16:49.651074Z","iopub.execute_input":"2023-08-07T08:16:49.653656Z","iopub.status.idle":"2023-08-07T08:16:50.526496Z","shell.execute_reply.started":"2023-08-07T08:16:49.653622Z","shell.execute_reply":"2023-08-07T08:16:50.525051Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout, hidden_dim, kernel_size):\n        super().__init__()\n        \n        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout, batch_first=True)\n        self.layer_norm = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(dropout)\n        \n        self.mlp = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            Rearrange('B S E -> B E S'),\n            nn.Conv1d(embed_dim, hidden_dim, kernel_size, padding = (kernel_size - 1) // 2),\n            #nn.Linear(embed_dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Conv1d(hidden_dim, embed_dim, kernel_size, padding = (kernel_size - 1) // 2),\n            #nn.Linear(hidden_dim, embed_dim),\n            nn.Dropout(dropout),\n            Rearrange('B E S-> B S E')\n        )\n        \n        self._init_weights()\n        \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n        \n    def forward(self, x, mask=None, fill_mask=None):\n        x.masked_fill_(fill_mask, 0.0)\n        attn_in = self.layer_norm(x)\n        attn_out, _ = self.attention(attn_in, attn_in, attn_in, key_padding_mask=mask)\n        x_out = attn_out + x\n        \n        x_out.masked_fill_(fill_mask, 0.0)\n        mlp_out = self.mlp(x_out)\n        out = mlp_out + x_out\n        out.masked_fill_(fill_mask, 0.0)\n        return out\n    \n    \nclass TransformerEncoder(nn.Module):\n    def __init__(self, embed_dim, hidden_dim, num_heads, num_layers, kernel_size, max_src_seq_len, src_vocab_size, dropout=0.0):\n        super().__init__()\n        \n        self.pos_embedding = PositionalEncoding(embed_dim, max_src_seq_len)\n        self.phone_embedding = nn.Embedding(src_vocab_size, embed_dim, padding_idx=0)\n        self.layers = nn.Sequential(*[TransformerBlock(embed_dim, num_heads, dropout, hidden_dim, kernel_size)  for _ in range(num_layers)])\n        \n    def forward(self, x, mask=None, fill_mask=None):\n        x = self.phone_embedding(x)\n        x = self.pos_embedding(x)\n        \n        for l in self.layers:\n            x = l(x, mask, fill_mask)\n        \n        return x\n        \nclass TransformerDecoder(nn.Module):\n    def __init__(self, embed_dim, hidden_dim, num_heads, num_layers, kernel_size, max_trg_seq_len, dropout=0.0):\n        super().__init__()\n        \n        self.pos_embedding = PositionalEncoding(embed_dim, max_trg_seq_len)\n        self.layers = nn.Sequential(*[TransformerBlock(embed_dim, num_heads, dropout, hidden_dim, kernel_size)  for _ in range(num_layers)])\n        \n    def forward(self, x, mask=None, fill_mask=None):\n        x = self.pos_embedding(x)\n        \n        for l in self.layers:\n            x = l(x, mask, fill_mask)\n        \n        return x\n        \nclass Hidden2Mel(nn.Module):\n    def __init__(self, embed_dim, n_mels):\n        super().__init__()\n        self.layers = nn.Linear(embed_dim, n_mels)\n        \n    def forward(self, x):\n        return self.layers(x)\n    \nclass LengthRegulator(nn.Module):\n    def __init__(self, max_trg_len=1000):\n        super().__init__()\n\n        self.max_trg_len = max_trg_len\n\n    def forward(self, encoder_output, variance):\n        B = encoder_output.shape[0]\n        mels = list()\n\n        for b_idx in range(B):\n            expanded_seq = torch.concat([ encoder_output[b_idx,i,:].expand(v, -1) for i, v in enumerate(variance[b_idx, :]) ], dim=0)\n            seq_len = expanded_seq.shape[0]\n            pad_len = self.max_trg_len - seq_len\n\n            if pad_len < 0:\n                padded_seq = expanded_seq[:self.max_trg_len, :]\n            elif pad_len > 0:\n                padded_seq = F.pad( expanded_seq, (0, 0, 0, pad_len), \"constant\", -1 )\n\n            mels.append(padded_seq)\n        expanded_batch = torch.stack(mels, dim=0)\n        return expanded_batch\n    \nclass FastSpeechLoss(nn.Module):\n    def __init__(self, encoder_max_seq_len, decoder_max_seq_len, mel_channels=80):\n        super().__init__()\n\n        self.mel_channels = mel_channels\n        self.encoder_max_seq_len = encoder_max_seq_len\n        self.decoder_max_seq_len = decoder_max_seq_len\n        self.mae_loss = nn.L1Loss()\n        self.mse_loss = nn.MSELoss()\n   \n    def forward(self, \n                h2m_predictions,\n                mel_targets,\n                p_predictions,\n                p_targets,\n                e_predictions,\n                e_targets,\n                log_d_predictions,\n                d_targets,\n                src_masks,\n                trg_masks\n               ):\n        \n        src_masks = ~src_masks\n        trg_masks = ~trg_masks\n        trg_masks = trg_masks[:, :, :self.mel_channels]\n        \n        d_targets.requires_grad = False\n        p_targets.requires_grad = False\n        e_targets.requires_grad = False\n        mel_targets.requires_grad = False\n        \n        log_d_targets = torch.log(d_targets.float() + 1)\n        \n        p_loss = self.mse_loss(p_predictions.masked_select(src_masks).float(), p_targets.masked_select(src_masks).float())\n        e_loss = self.mse_loss(e_predictions.masked_select(src_masks).float(), e_targets.masked_select(src_masks).float())\n        d_loss = self.mse_loss(log_d_predictions.masked_select(src_masks).float(), log_d_targets.masked_select(src_masks).float())\n        h2m_loss = self.mae_loss(mel_targets.masked_select(trg_masks), h2m_predictions.masked_select(trg_masks))\n        \n        total_loss = p_loss + e_loss + d_loss + h2m_loss\n    \n        return (total_loss, h2m_loss, e_loss, p_loss, d_loss)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:16:50.534342Z","iopub.execute_input":"2023-08-07T08:16:50.534883Z","iopub.status.idle":"2023-08-07T08:16:50.603298Z","shell.execute_reply.started":"2023-08-07T08:16:50.534825Z","shell.execute_reply":"2023-08-07T08:16:50.601974Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Variance Predictor and Adaptor Start","metadata":{}},{"cell_type":"code","source":"class Conv(nn.Module):\n    \"\"\"\n    Convolution Module\n    \"\"\"\n\n    def __init__(\n        self,\n        in_channels,\n        out_channels,\n        kernel_size=1,\n        stride=1,\n        padding=0,\n        dilation=1,\n        bias=True,\n        w_init=\"linear\",\n    ):\n        \"\"\"\n        :param in_channels: dimension of input\n        :param out_channels: dimension of output\n        :param kernel_size: size of kernel\n        :param stride: size of stride\n        :param padding: size of padding\n        :param dilation: dilation rate\n        :param bias: boolean. if True, bias is included.\n        :param w_init: str. weight inits with xavier initialization.\n        \"\"\"\n        super(Conv, self).__init__()\n\n        self.conv = nn.Conv1d(\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            dilation=dilation,\n            bias=bias,\n        )\n\n    def forward(self, x):\n        x = x.contiguous().transpose(1, 2)\n        x = self.conv(x)\n        x = x.contiguous().transpose(1, 2)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:16:50.961650Z","iopub.execute_input":"2023-08-07T08:16:50.962394Z","iopub.status.idle":"2023-08-07T08:16:50.973170Z","shell.execute_reply.started":"2023-08-07T08:16:50.962358Z","shell.execute_reply":"2023-08-07T08:16:50.972081Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class VariancePredictor(nn.Module):\n    def __init__(self, input_size, filter_size, kernel, conv_output_size, dropout):\n        super(VariancePredictor, self).__init__()\n        self.input_size = input_size\n        self.filter_size = filter_size\n        self.kernel = kernel\n        self.conv_output_size = conv_output_size\n        self.dropout = dropout\n        \n        self.conv_layer = nn.Sequential(\n            OrderedDict(\n                [\n                    (\n                        \"conv1d_1\",\n                        Conv(\n                            self.input_size,\n                            self.filter_size,\n                            kernel_size=self.kernel,\n                            padding=(self.kernel - 1) // 2,\n                        ),\n                    ),\n                    (\"relu_1\", nn.ReLU()),\n                    (\"layer_norm_1\", nn.LayerNorm(self.filter_size)),\n                    (\"dropout_1\", nn.Dropout(self.dropout)),\n                    (\n                        \"conv1d_2\",\n                        Conv(\n                            self.filter_size,\n                            self.filter_size,\n                            kernel_size=self.kernel,\n                            padding=1,\n                        ),\n                    ),\n                    (\"relu_2\", nn.ReLU()),\n                    (\"layer_norm_2\", nn.LayerNorm(self.filter_size)),\n                    (\"dropout_2\", nn.Dropout(self.dropout)),\n                ]\n            )\n        )\n\n        self.linear_layer = nn.Linear(self.conv_output_size, 1)\n\n    def forward(self, encoder_output, mask):\n        out = self.conv_layer(encoder_output)\n        out = self.linear_layer(out)\n        out = out.squeeze(-1)\n\n        if mask is not None:\n            out = out.masked_fill(mask, 0.0)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:16:51.702390Z","iopub.execute_input":"2023-08-07T08:16:51.702814Z","iopub.status.idle":"2023-08-07T08:16:51.716937Z","shell.execute_reply.started":"2023-08-07T08:16:51.702780Z","shell.execute_reply":"2023-08-07T08:16:51.715810Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class VarianceAdaptor(nn.Module):\n    \"\"\"Variance Adaptor\"\"\"\n\n    def __init__(self, \n                 stats_path,\n                 input_size=256,\n                 filter_size=256,\n                 kernel=3,\n                 conv_output_size=256,\n                 dropout=0.5,\n                 quantization='linear',\n                 quantization_n_bins=256,\n                 feature_level='phoneme_level'):\n        super(VarianceAdaptor, self).__init__()\n        self.duration_predictor = VariancePredictor(input_size, filter_size, kernel, conv_output_size, dropout)\n        self.length_regulator = LengthRegulator()\n        self.pitch_predictor = VariancePredictor(input_size, filter_size, kernel, conv_output_size, dropout)\n        self.energy_predictor = VariancePredictor(input_size, filter_size, kernel, conv_output_size, dropout)\n        self.pitch_feature_level = feature_level\n        self.energy_feature_level = feature_level\n\n        pitch_quantization = quantization\n        energy_quantization = quantization\n        n_bins = quantization_n_bins\n        \n        assert pitch_quantization in [\"linear\", \"log\"]\n        assert energy_quantization in [\"linear\", \"log\"]\n        \n        with open(\n            os.path.join(stats_path, \"stats.json\")\n        ) as f:\n            stats = json.load(f)\n            pitch_min, pitch_max = stats[\"pitch\"][:2]\n            energy_min, energy_max = stats[\"energy\"][:2]\n\n        if pitch_quantization == \"log\":\n            self.pitch_bins = nn.Parameter(\n                torch.exp(\n                    torch.linspace(np.log(pitch_min), np.log(pitch_max), n_bins - 1)\n                ),\n                requires_grad=False,\n            )\n        else:\n            self.pitch_bins = nn.Parameter(\n                torch.linspace(pitch_min, pitch_max, n_bins - 1),\n                requires_grad=False,\n            )\n        if energy_quantization == \"log\":\n            self.energy_bins = nn.Parameter(\n                torch.exp(\n                    torch.linspace(np.log(energy_min), np.log(energy_max), n_bins - 1)\n                ),\n                requires_grad=False,\n            )\n        else:\n            self.energy_bins = nn.Parameter(\n                torch.linspace(energy_min, energy_max, n_bins - 1),\n                requires_grad=False,\n            )\n\n        self.pitch_embedding = nn.Embedding(\n            n_bins, input_size\n        )\n        self.energy_embedding = nn.Embedding(\n            n_bins, input_size\n        )\n\n    def get_pitch_embedding(self, x, target, mask, control):\n        prediction = self.pitch_predictor(x, mask)\n        if target is not None:\n            embedding = self.pitch_embedding(torch.bucketize(target, self.pitch_bins))\n        else:\n            prediction = prediction * control\n            embedding = self.pitch_embedding(\n                torch.bucketize(prediction, self.pitch_bins)\n            )\n        return prediction, embedding\n\n    def get_energy_embedding(self, x, target, mask, control):\n        prediction = self.energy_predictor(x, mask)\n        if target is not None:\n            embedding = self.energy_embedding(torch.bucketize(target, self.energy_bins))\n        else:\n            prediction = prediction * control\n            embedding = self.energy_embedding(\n                torch.bucketize(prediction, self.energy_bins)\n            )\n        return prediction, embedding\n\n    def forward(\n        self,\n        x,\n        src_mask,\n        mel_mask=None,\n        max_len=None,\n        pitch_target=None,\n        energy_target=None,\n        duration_target=None,\n        p_control=1.0,\n        e_control=1.0,\n        d_control=1.0,\n    ):\n\n        log_duration_prediction = self.duration_predictor(x, src_mask)\n        \n        if self.pitch_feature_level == \"phoneme_level\":\n            pitch_prediction, pitch_embedding = self.get_pitch_embedding(\n                x, pitch_target, src_mask, p_control\n            )\n            x = x + pitch_embedding\n\n        if self.energy_feature_level == \"phoneme_level\":\n            energy_prediction, energy_embedding = self.get_energy_embedding(\n                x, energy_target, src_mask, p_control\n            )\n            x = x + energy_embedding\n\n        if duration_target is not None:\n            x = self.length_regulator(x, duration_target)\n            duration_rounded = duration_target\n        else:\n            duration_rounded = torch.clamp(\n                (torch.round(torch.exp(log_duration_prediction) - 1) * d_control),\n                min=0,\n            ).type(torch.LongTensor)\n            x = self.length_regulator(x, duration_rounded)\n\n        return (\n            x,\n            pitch_prediction,\n            energy_prediction,\n            log_duration_prediction,\n            duration_rounded,\n        )","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:21:12.269193Z","iopub.execute_input":"2023-08-07T08:21:12.269614Z","iopub.status.idle":"2023-08-07T08:21:12.297074Z","shell.execute_reply.started":"2023-08-07T08:21:12.269581Z","shell.execute_reply":"2023-08-07T08:21:12.295336Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class FastSpeech(nn.Module):\n    def __init__(self, \n                 stats_path,\n                 num_heads=2,\n                 num_layers=6,\n                 dropout=0.0,\n                 embed_dim=256,\n                 hidden_dim=512,\n                 kernel_size=3,\n                 max_trg_seq_len=1000,\n                 max_src_seq_len=200,\n                 src_vocab_size=360,\n                 n_mels=80,\n                 input_size=256,\n                 filter_size=256,\n                 kernel=3,\n                 conv_output_size=256,\n                 variance_adaptor_dropout=0.5,\n                 quantization='linear',\n                 quantization_n_bins=256,\n                 feature_level='phoneme_level'\n                ):\n        super().__init__()\n        self.encoder_max_seq_len = max_src_seq_len\n        self.decoder_max_seq_len = max_trg_seq_len\n        self.embed_dim = embed_dim\n        self.n_mels = n_mels\n        \n        self.variance_adaptor = VarianceAdaptor(stats_path, \n                                                input_size=input_size,\n                                                filter_size=filter_size,\n                                                kernel=kernel,\n                                                conv_output_size=conv_output_size,\n                                                dropout=variance_adaptor_dropout,\n                                                quantization=quantization,\n                                                quantization_n_bins=quantization_n_bins,\n                                                feature_level=feature_level)\n        \n        self.encoder = TransformerEncoder(num_heads=num_heads,\n                                          num_layers=num_layers,\n                                          dropout=dropout,\n                                          embed_dim=embed_dim,\n                                          hidden_dim=hidden_dim,\n                                          kernel_size=kernel_size,\n                                          src_vocab_size=src_vocab_size,\n                                          max_src_seq_len=max_src_seq_len)\n        \n        self.decoder = TransformerDecoder(num_heads=num_heads,\n                                          num_layers=num_layers,\n                                          dropout=dropout,\n                                          embed_dim=embed_dim,\n                                          hidden_dim=hidden_dim,\n                                          kernel_size=kernel_size,\n                                          max_trg_seq_len=max_trg_seq_len)\n        \n        self.hidden2mel = Hidden2Mel(n_mels=n_mels, embed_dim=embed_dim)\n        \n        self.length_regulator = LengthRegulator(max_trg_seq_len)\n        \n    def _get_masks(self, seq_lens, max_seq_len, embed_dim):\n        B = seq_lens.shape[0]\n        masks = [[ mask_idx >= seq_lens[seq_idx]  for mask_idx in torch.arange(max_seq_len)]  for seq_idx in torch.arange(0, B)]\n        masks = torch.tensor(masks)\n        fill_masks = repeat(masks.T, 'b s -> e b s', e=embed_dim).T.contiguous()\n        \n        return masks.to(device), fill_masks.to(device)\n        \n    def forward(self, src_seq, src_seq_len, trg_seq, trg_seq_len, trg_durations, trg_energy, trg_pitch):\n        src_masks, src_fill_masks = self._get_masks(src_seq_len, self.encoder_max_seq_len, self.embed_dim)\n        trg_masks, trg_fill_masks = self._get_masks(trg_seq_len, self.decoder_max_seq_len, self.embed_dim)\n        mel_masks, mel_fill_masks = self._get_masks(trg_seq_len, self.decoder_max_seq_len, self.n_mels)\n        \n        enc_out = self.encoder(src_seq, src_masks, src_fill_masks)\n#         adapted_enc_out = self.length_regulator(enc_out, trg_durations)\n\n        (adapted_enc_out, \n        p_predictions,\n        e_predictions,\n        log_d_predictions,\n        d_rounded) = self.variance_adaptor(\n            enc_out,\n            src_masks,\n            mel_mask=trg_masks,\n            duration_target=trg_durations)\n        \n        dec_out = self.decoder(adapted_enc_out, trg_masks, trg_fill_masks)\n        h2m_out = self.hidden2mel(dec_out).masked_fill(mel_fill_masks, 0.0)\n        \n        return (h2m_out,\n                p_predictions,\n                e_predictions,\n                log_d_predictions,\n                d_rounded,\n                src_masks,\n                mel_fill_masks)\n    \n\n# model = FastSpeech(\n#     './preprocessed_data/SpanishSingleSpeaker',\n#     num_heads=2,\n#     num_layers=6,\n#     dropout=0.0, \n#     embed_dim=256,\n#     hidden_dim=512,\n#     kernel_size=3,\n#     max_trg_seq_len=1000,\n#     max_src_seq_len=200,\n#     n_mels=80,\n#     src_vocab_size=len(_symbol_to_id)\n# )\n\n# phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch = next(iter(train_loader))\n\n# (h2m_predictions,\n# p_predictions,\n# e_predictions,\n# log_d_predictions,\n# d_rounded,\n# src_masks,\n# trg_masks) = model(phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch)\n\nprint('Success')","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:21:14.614893Z","iopub.execute_input":"2023-08-07T08:21:14.615354Z","iopub.status.idle":"2023-08-07T08:21:14.646012Z","shell.execute_reply.started":"2023-08-07T08:21:14.615322Z","shell.execute_reply":"2023-08-07T08:21:14.642465Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Success\n","output_type":"stream"}]},{"cell_type":"code","source":"t, m, v, s, d = FastSpeechLoss(200, 1000)(h2m_predictions,\n                          mels,\n                          p_predictions,\n                          pitch,\n                          e_predictions,\n                          energy,\n                          log_d_predictions,\n                          durations,\n                          src_masks,\n                          trg_masks)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:21:16.210750Z","iopub.execute_input":"2023-08-07T08:21:16.211147Z","iopub.status.idle":"2023-08-07T08:21:16.277276Z","shell.execute_reply.started":"2023-08-07T08:21:16.211111Z","shell.execute_reply":"2023-08-07T08:21:16.275929Z"},"trusted":true},"execution_count":31,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m t, m, v, s, d \u001b[38;5;241m=\u001b[39m FastSpeechLoss(\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m1000\u001b[39m)(\u001b[43mh2m_predictions\u001b[49m,\n\u001b[1;32m      2\u001b[0m                           mels,\n\u001b[1;32m      3\u001b[0m                           p_predictions,\n\u001b[1;32m      4\u001b[0m                           pitch,\n\u001b[1;32m      5\u001b[0m                           e_predictions,\n\u001b[1;32m      6\u001b[0m                           energy,\n\u001b[1;32m      7\u001b[0m                           log_d_predictions,\n\u001b[1;32m      8\u001b[0m                           durations,\n\u001b[1;32m      9\u001b[0m                           src_masks,\n\u001b[1;32m     10\u001b[0m                           trg_masks)\n","\u001b[0;31mNameError\u001b[0m: name 'h2m_predictions' is not defined"],"ename":"NameError","evalue":"name 'h2m_predictions' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"### Variance Predictor and Adaptor End","metadata":{}},{"cell_type":"code","source":"class FastSpeechModule(pl.LightningModule):\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = FastSpeech(\n#                         './preprocessed_data/SpanishSingleSpeaker',\n                        './preprocessed_data/LJSpeech',\n                        num_heads=2,\n                        num_layers=6,\n                        dropout=0.0, \n                        embed_dim=256,\n                        hidden_dim=512,\n                        kernel_size=3,\n                        max_trg_seq_len=1000,\n                        max_src_seq_len=200,\n                        n_mels=80,\n                        src_vocab_size=len(_symbol_to_id)\n                    )\n        \n        self.loss_module = FastSpeechLoss(encoder_max_seq_len=200, decoder_max_seq_len=1000)\n        \n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n        return [optimizer], [lr_scheduler]\n    \n    def training_step(self, batch, batch_idx):\n        phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch = batch\n        \n        (\n            h2m_predictions,\n            p_predictions,\n            e_predictions,\n            log_d_predictions,\n            d_rounded,\n            src_masks,\n            trg_masks\n        ) = self.model(phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch)\n        \n        \n        (\n            total_loss,\n            h2m_loss,\n            e_loss,\n            p_loss,\n            d_loss) = self.loss_module(\n            h2m_predictions,\n            mels,\n            p_predictions,\n            pitch,\n            e_predictions,\n            energy,\n            log_d_predictions,\n            durations,\n            src_masks,\n            trg_masks\n        )\n        \n        self.log(f'train_total_loss', total_loss, on_step=True, on_epoch=True)\n        self.log(f'train_h2m_loss', h2m_loss, on_step=True, on_epoch=True)\n        self.log(f'train_e_loss', e_loss, on_step=True, on_epoch=True)\n        self.log(f'train_d_loss', d_loss, on_step=True, on_epoch=True)\n        self.log(f'train_p_loss', p_loss, on_step=True, on_epoch=True)\n        \n        if self.current_epoch in [100, 150, 198, 298]:\n            inv_mel_spec(h2m_predictions[0].T, f'file_{self.current_epoch}.wav', stft)\n            print('synth')\n        \n        return total_loss\n    \n    def validation_step(self, batch, batch_idx):\n        phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch = batch\n        \n        (\n            h2m_predictions,\n            p_predictions,\n            e_predictions,\n            log_d_predictions,\n            d_rounded,\n            src_masks,\n            trg_masks\n        ) = self.model(phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch)\n        \n        \n        (\n            total_loss,\n            h2m_loss,\n            e_loss,\n            p_loss,\n            d_loss) = self.loss_module(\n            h2m_predictions,\n            mels,\n            p_predictions,\n            pitch,\n            e_predictions,\n            energy,\n            log_d_predictions,\n            durations,\n            src_masks,\n            trg_masks\n        )\n        \n        self.log(f'val_total_loss', total_loss, on_step=True, on_epoch=True)\n        self.log(f'val_h2m_loss', h2m_loss, on_step=True, on_epoch=True)\n        self.log(f'val_e_loss', e_loss, on_step=True, on_epoch=True)\n        self.log(f'val_d_loss', d_loss, on_step=True, on_epoch=True)\n        self.log(f'val_p_loss', p_loss, on_step=True, on_epoch=True)   \n    \n    def test_step(self, batch, batch_idx):\n        phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch = batch\n        \n        (\n            h2m_predictions,\n            p_predictions,\n            e_predictions,\n            log_d_predictions,\n            d_rounded,\n            src_masks,\n            trg_masks\n        ) = self.model(phonemes, phoneme_lens, mels, mel_lens, durations, energy, pitch)\n        \n        (\n            total_loss,\n            h2m_loss,\n            e_loss,\n            p_loss,\n            d_loss) = self.loss_module(\n            h2m_predictions,\n            mels,\n            p_predictions,\n            pitch,\n            e_predictions,\n            energy,\n            log_d_predictions,\n            durations,\n            src_masks,\n            trg_masks\n        )\n        \n        self.log(f'test_total_loss', total_loss, on_step=True, on_epoch=True)\n        self.log(f'test_h2m_loss', h2m_loss, on_step=True, on_epoch=True)\n        self.log(f'test_e_loss', e_loss, on_step=True, on_epoch=True)\n        self.log(f'test_d_loss', d_loss, on_step=True, on_epoch=True)\n        self.log(f'test_p_loss', p_loss, on_step=True, on_epoch=True)   ","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:21:18.673739Z","iopub.execute_input":"2023-08-07T08:21:18.674139Z","iopub.status.idle":"2023-08-07T08:21:18.704669Z","shell.execute_reply.started":"2023-08-07T08:21:18.674107Z","shell.execute_reply":"2023-08-07T08:21:18.703211Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.finish()\nwandb_logger = WandbLogger(project='Fast Speech 2 - Improved', name='LJ Speech with var adapter 1')","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:21:21.234110Z","iopub.execute_input":"2023-08-07T08:21:21.235252Z","iopub.status.idle":"2023-08-07T08:21:58.297799Z","shell.execute_reply.started":"2023-08-07T08:21:21.235214Z","shell.execute_reply":"2023-08-07T08:21:58.296922Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">LJ Speech with var adapter 1</strong> at: <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/g7i5dbuj' target=\"_blank\">https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/g7i5dbuj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230807_081753-g7i5dbuj/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20230807_082127-u5xmpx4z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/u5xmpx4z' target=\"_blank\">LJ Speech with var adapter 1</a></strong> to <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved' target=\"_blank\">https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/u5xmpx4z' target=\"_blank\">https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/u5xmpx4z</a>"},"metadata":{}}]},{"cell_type":"code","source":"def train_model(**kwargs):\n    trainer = pl.Trainer(default_root_dir=os.path.join('checkpoints', 'initial model x'),\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=300,\n                         logger=wandb_logger,\n                         overfit_batches=1,\n                         callbacks=[\n                             ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_total_loss\"),\n                                    LearningRateMonitor(\"epoch\")]\n                        )\n    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    pl.seed_everything(42) # To be reproducable\n    model = FastSpeechModule(**kwargs)\n    trainer.fit(model, train_loader, val_loader)\n    model = FastSpeechModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n\n    # Test best model on validation and test set\n    val_result = trainer.test(model, val_loader, verbose=False)\n    result = {\"val\": val_result[0][\"test_loss\"]}\n    return model, result\n\nmodel, results = train_model(lr=3e-4)","metadata":{"execution":{"iopub.status.busy":"2023-08-07T08:22:27.522700Z","iopub.execute_input":"2023-08-07T08:22:27.523106Z","iopub.status.idle":"2023-08-07T08:27:56.512641Z","shell.execute_reply.started":"2023-08-07T08:22:27.523072Z","shell.execute_reply":"2023-08-07T08:27:56.509655Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1144: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/transformers/attention.cpp:150.)\n  return torch._native_multi_head_attention(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5840a9e04ff446a81d8642ef63aef99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea85dcd8eae64ffaa5b60dfeadedf29a"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[34], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, result\n\u001b[0;32m---> 26\u001b[0m model, results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[34], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Test best model on validation and test set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m val_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(model, val_loader, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mval_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m}\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, result\n","\u001b[0;31mKeyError\u001b[0m: 'test_loss'"],"ename":"KeyError","evalue":"'test_loss'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ViT Stuff","metadata":{}},{"cell_type":"code","source":"class VisionTransformer(nn.Module):\n    def __init__(self, embed_dim, hidden_dim, num_channels, num_heads, num_layers, num_classes, patch_size, num_patches, kernel_size, dropout=0.0):\n        super().__init__()\n        \n        input_dim = patch_size * patch_size * num_channels\n        \n        self.input_net = nn.Sequential(\n            Rearrange('B C (h p1) (w p2) -> B (h w) (C p1 p2)', p1=patch_size, p2=patch_size),\n            nn.Linear(input_dim, embed_dim)\n        )\n        \n        self.positional_embedding = nn.Embedding(num_patches + 1, embed_dim) # +1 for the CLS token\n        \n        self.mlp = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            nn.Linear(embed_dim, num_classes),\n        )\n        \n        self.encoder = nn.Sequential(*[\n            TransformerBlock(embed_dim, num_heads, dropout, hidden_dim, kernel_size) for _ in range(num_layers)\n        ])\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n        \n    def forward(self, x):\n        x = self.input_net(x)\n        B, T, _ = x.shape\n        cls_token = repeat(self.cls_token, '1 1 N -> B 1 N', B=B)\n        x = torch.cat([cls_token, x], dim=1)\n        pos = torch.arange(0, T+1).to(device)\n        x = x + self.positional_embedding(pos)\n        x = self.dropout(x)\n        x = self.encoder(x)\n        out = self.mlp(x[:, 0, :])\n        return out\n    \nt = VisionTransformer(**{ 'embed_dim': 256,\n                                'hidden_dim': 512,\n                                'num_heads': 8,\n                                'num_layers': 6,\n                                'patch_size': 4,\n                                'num_channels': 3,\n                                'num_patches': 64,\n                                'num_classes': 10,\n                                'dropout': 0.2,\n                                'kernel_size': 3\n                        })\n\n# t(torch.randn(6, 3, 32, 32)).shape\n\nclass ViT(pl.LightningModule):\n\n    def __init__(self, model_kwargs, lr):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = VisionTransformer(**model_kwargs)\n        self.example_input_array = next(iter(train_loader))[0]\n\n    def forward(self, x):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n        return [optimizer], [lr_scheduler]\n\n    def _calculate_loss(self, batch, mode=\"train\"):\n        imgs, labels = batch\n        preds = self.model(imgs)\n        loss = F.cross_entropy(preds, labels)\n        acc = (preds.argmax(dim=-1) == labels).float().mean()\n\n        self.log(f'{mode}_loss', loss, on_step=True, on_epoch=True)\n        self.log(f'{mode}_acc', acc, on_step=True, on_epoch=True)\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        loss = self._calculate_loss(batch, mode=\"train\")\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        self._calculate_loss(batch, mode=\"val\")\n\n    def test_step(self, batch, batch_idx):\n        self._calculate_loss(batch, mode=\"test\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()\nwandb_logger = WandbLogger(project='FastSpeech2', name='ViT CNN v2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(**kwargs):\n    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"ViT CNN\"),\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=180,\n                         logger=wandb_logger,\n                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n                                    LearningRateMonitor(\"epoch\")])\n    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    pl.seed_everything(42) # To be reproducable\n    model = ViT(**kwargs)\n    trainer.fit(model, train_loader, val_loader)\n    model = ViT.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n\n    # Test best model on validation and test set\n    val_result = trainer.test(model, val_loader, verbose=False)\n    test_result = trainer.test(model, test_loader, verbose=False)\n    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n    return model, result\n\nmodel, results = train_model(model_kwargs={\n                                'embed_dim': 256,\n                                'hidden_dim': 512,\n                                'num_heads': 8,\n                                'num_layers': 6,\n                                'patch_size': 4,\n                                'num_channels': 3,\n                                'num_patches': 64,\n                                'num_classes': 10,\n                                'dropout': 0.2,\n                                'kernel_size': 3\n                            },\n                            lr=3e-4)\n\nprint(\"ViT results\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}