{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyworld inflect tgt einops","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-29T20:49:59.991574Z","iopub.execute_input":"2023-07-29T20:49:59.992017Z","iopub.status.idle":"2023-07-29T20:50:48.810864Z","shell.execute_reply.started":"2023-07-29T20:49:59.991978Z","shell.execute_reply":"2023-07-29T20:50:48.809637Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyworld\n  Downloading pyworld-0.3.4.tar.gz (251 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting inflect\n  Downloading inflect-7.0.0-py3-none-any.whl (34 kB)\nCollecting tgt\n  Downloading tgt-1.4.4.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pyworld) (1.23.5)\nRequirement already satisfied: cython>=0.24 in /opt/conda/lib/python3.10/site-packages (from pyworld) (0.29.34)\nRequirement already satisfied: pydantic>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from inflect) (1.10.7)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from inflect) (4.5.0)\nBuilding wheels for collected packages: pyworld, tgt\n  Building wheel for pyworld (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=202816 sha256=fce0ed9632444b3d9f016a4d9f2ecc532b868c240e013095c92a515b78f4b970\n  Stored in directory: /root/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\n  Building wheel for tgt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tgt: filename=tgt-1.4.4-py3-none-any.whl size=28929 sha256=14c5688c17b09bb66fd0520638c82ee8bfdde7f7f329d1c272d53307cfd42dcf\n  Stored in directory: /root/.cache/pip/wheels/09/e6/aa/821531faeb4e05a65d1c763570e90791467cf0c3f1622dc7e2\nSuccessfully built pyworld tgt\nInstalling collected packages: tgt, pyworld, einops, inflect\nSuccessfully installed einops-0.6.1 inflect-7.0.0 pyworld-0.3.4 tgt-1.4.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"## Standard libraries\nimport os\nimport numpy as np\nimport pandas as pd \nimport random\nimport math\nimport json\nfrom functools import partial\nfrom PIL import Image\nimport wandb\nfrom einops import rearrange, reduce, repeat\nfrom einops.layers.torch import Rearrange\n\n## tqdm for loading bars\nfrom tqdm.notebook import tqdm\n\n## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\n# PyTorch Lightning\ntry:\n    import pytorch_lightning as pl\nexcept ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n    !pip install --quiet pytorch-lightning>=1.4\n    import pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n\n# Setting the seed\npl.seed_everything(42)\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\nfrom pytorch_lightning.loggers import WandbLogger\nwandb_api_key = '430e8c7ef92cf79a3d7c3d02e3d961257153181f'\nos.environ[\"WANDB_API_KEY\"] = wandb_api_key\n\nimport sys; sys.path.insert(0, '/..')\nos.chdir(os.path.join(os.getcwd(), 'masters-final'))\n\n\nfrom text import _clean_text\nfrom text import _symbol_to_id","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:50:48.813382Z","iopub.execute_input":"2023-07-29T20:50:48.813762Z","iopub.status.idle":"2023-07-29T20:51:03.066315Z","shell.execute_reply.started":"2023-07-29T20:50:48.813727Z","shell.execute_reply":"2023-07-29T20:51:03.065319Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"from audio.tools import inv_mel_spec\nfrom audio.stft import TacotronSTFT","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:03.067799Z","iopub.execute_input":"2023-07-29T20:51:03.068565Z","iopub.status.idle":"2023-07-29T20:51:09.566452Z","shell.execute_reply.started":"2023-07-29T20:51:03.068530Z","shell.execute_reply":"2023-07-29T20:51:09.565540Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# # Run the following if it's the first time running in this kernel\n# # !git clone https://github.com/SitholeDavid/masters-final\n!git pull","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:09.569017Z","iopub.execute_input":"2023-07-29T20:51:09.569514Z","iopub.status.idle":"2023-07-29T20:51:11.107299Z","shell.execute_reply.started":"2023-07-29T20:51:09.569480Z","shell.execute_reply":"2023-07-29T20:51:11.106130Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Already up to date.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import librosa.display\n# mel_spec = torch.from_numpy(np.load('./preprocessed_data/LJSpeech/mel/LJSpeech-mel-LJ048-0114.npy'))\n# # mel_spec = torch.from_numpy(np.load('/kaggle/working/masters-final/preprocessed_data/SpanishSingleSpeaker/mel/SpanishSingleSpeaker-mel-19demarzo_0022.npy'))\n# librosa.display.specshow(mel_spec.T.numpy())\n# stft = TacotronSTFT(filter_length=1024, hop_length=256, win_length=1024, n_mel_channels=80, sampling_rate=22050, mel_fmin=0, mel_fmax=8000)\n# inv_mel_spec(mel_spec.T, 'file.wav', stft)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:11.110192Z","iopub.execute_input":"2023-07-29T20:51:11.110967Z","iopub.status.idle":"2023-07-29T20:51:11.116264Z","shell.execute_reply.started":"2023-07-29T20:51:11.110906Z","shell.execute_reply":"2023-07-29T20:51:11.115323Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Prepare Spanish Dataset","metadata":{}},{"cell_type":"code","source":"# !python3 prepare_align.py config/SpanishSingleSpeaker/preprocess.yaml\n# !python3 preprocess.py config/SpanishSingleSpeaker/preprocess.yaml","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:03:32.792918Z","iopub.execute_input":"2023-07-29T20:03:32.793370Z","iopub.status.idle":"2023-07-29T20:03:32.798253Z","shell.execute_reply.started":"2023-07-29T20:03:32.793334Z","shell.execute_reply":"2023-07-29T20:03:32.797405Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Dataset and Loaders","metadata":{}},{"cell_type":"code","source":"class SpanishDataset(Dataset):\n    def __init__(self,  input_dir, input_file, max_src_len, max_trg_len):\n        self.input_dir = input_dir\n        self.max_src_len = max_src_len\n        self.max_trg_len = max_trg_len\n        \n        files = pd.read_csv(os.path.join(input_dir, input_file), sep='|', header=None)\n        files.columns = ['file', 'speaker', 'phones', 'text'] \n        \n        # only consider valid phoneme sequences\n        for index, row in tqdm(files.iterrows(), total=len(files)):\n            if not all(symbol in _symbol_to_id for symbol in self._process_phones(row['phones'])):\n                files.drop(index, inplace=True)\n\n        self.file_names = files\n\n    def _process_phones(self, phones):\n        phones = phones.replace('{', '').replace('}', '').strip().split(' ')\n        mapped_phones = [f'@{phone}' for phone in phones]\n        return mapped_phones\n        \n    def __len__(self):\n        return len(self.file_names)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names.iloc[idx]['file']\n        \n        mel = np.load(os.path.join(self.input_dir, 'mel', f'SpanishSingleSpeaker-mel-{file_name}.npy'))\n        duration = np.load(os.path.join(self.input_dir, 'duration', f'SpanishSingleSpeaker-duration-{file_name}.npy'))\n        energy = np.load(os.path.join(self.input_dir, 'energy', f'SpanishSingleSpeaker-energy-{file_name}.npy'))\n        pitch = np.load(os.path.join(self.input_dir, 'pitch', f'SpanishSingleSpeaker-pitch-{file_name}.npy'))\n        phones = self._process_phones(self.file_names.iloc[idx]['phones'])\n        \n        phone_mapping = torch.tensor([ _symbol_to_id[symbol] for symbol in phones ])\n\n        src_len = torch.tensor(len(phones))\n        trg_len = torch.tensor(mel.shape[0])\n\n        phoneme_pad_length = self.max_src_len - src_len\n        mel_pad_length = self.max_trg_len - trg_len\n        \n        phone_mapping = F.pad(phone_mapping, (0, phoneme_pad_length), mode='constant', value=0)\n        duration = F.pad( torch.tensor(duration), (0, phoneme_pad_length), mode='constant', value=0)\n        energy = F.pad( torch.tensor(energy), (0, phoneme_pad_length), mode='constant', value=0)\n        pitch = F.pad( torch.tensor(pitch), (0, phoneme_pad_length), mode='constant', value=0)\n        mel = F.pad(torch.tensor(mel), (0, 0, 0, mel_pad_length), mode='constant', value=0)\n        return  phone_mapping, src_len, mel, trg_len, duration\n    \ntrain_dataset = SpanishDataset('./preprocessed_data/SpanishSingleSpeaker', 'train.txt', max_src_len=200, max_trg_len=1000)\nval_dataset = SpanishDataset('./preprocessed_data/SpanishSingleSpeaker', 'val.txt', max_src_len=200, max_trg_len=1000)\n\n# set shuffle to false since we already shuffle when the data is split into train/test\ntrain_loader = DataLoader(train_dataset, shuffle=False, batch_size=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, shuffle=False, batch_size=4)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:11.118154Z","iopub.execute_input":"2023-07-29T20:51:11.118859Z","iopub.status.idle":"2023-07-29T20:51:12.165134Z","shell.execute_reply.started":"2023-07-29T20:51:11.118827Z","shell.execute_reply":"2023-07-29T20:51:12.163998Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10437 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb7794e10414fb39f667ea3d62f1b60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/512 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a146c0edbc3f453d83874d300caf86d2"}},"metadata":{}}]},{"cell_type":"code","source":"class LJSpeechDataset(Dataset):\n    def __init__(self,  input_dir, input_file, max_src_len, max_trg_len):\n        self.input_dir = input_dir\n        self.max_src_len = max_src_len\n        self.max_trg_len = max_trg_len\n        \n        files = pd.read_csv(os.path.join(input_dir, input_file), sep='|', header=None)\n        files.columns = ['file', 'speaker', 'phones', 'text'] \n        \n        # only consider valid phoneme sequences\n        for index, row in tqdm(files.iterrows(), total=len(files)):\n            if not all(symbol in _symbol_to_id for symbol in self._process_phones(row['phones'])):\n                files.drop(index, inplace=True)\n\n        self.file_names = files\n\n    def _process_phones(self, phones):\n        phones = phones.replace('{', '').replace('}', '').strip().split(' ')\n        mapped_phones = [f'@{phone}' if str.isalnum(phone) else phone for phone in phones]\n        return mapped_phones\n        \n    def __len__(self):\n        return len(self.file_names)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names.iloc[idx]['file']\n        \n        mel = np.load(os.path.join(self.input_dir, 'mel', f'LJSpeech-mel-{file_name}.npy'))\n        duration = np.load(os.path.join(self.input_dir, 'duration', f'LJSpeech-duration-{file_name}.npy'))\n        energy = np.load(os.path.join(self.input_dir, 'energy', f'LJSpeech-energy-{file_name}.npy'))\n        pitch = np.load(os.path.join(self.input_dir, 'pitch', f'LJSpeech-pitch-{file_name}.npy'))\n        phones = self._process_phones(self.file_names.iloc[idx]['phones'])\n        \n        phone_mapping = torch.tensor([ _symbol_to_id[symbol] for symbol in phones ])\n\n        src_len = torch.tensor(len(phones))\n        trg_len = torch.tensor(mel.shape[0])\n\n        phoneme_pad_length = self.max_src_len - src_len\n        mel_pad_length = self.max_trg_len - trg_len\n        \n        phone_mapping = F.pad(phone_mapping, (0, phoneme_pad_length), mode='constant', value=0)\n        duration = F.pad( torch.tensor(duration), (0, phoneme_pad_length), mode='constant', value=0)\n        energy = F.pad( torch.tensor(energy), (0, phoneme_pad_length), mode='constant', value=0)\n        pitch = F.pad( torch.tensor(pitch), (0, phoneme_pad_length), mode='constant', value=0)\n        mel = F.pad(torch.tensor(mel), (0, 0, 0, mel_pad_length), mode='constant', value=0)\n        return  phone_mapping, src_len, mel, trg_len, duration\n    \ntrain_dataset = LJSpeechDataset('./preprocessed_data/LJSpeech', 'train.txt', max_src_len=200, max_trg_len=1000)\nval_dataset = LJSpeechDataset('./preprocessed_data/LJSpeech', 'val.txt', max_src_len=200, max_trg_len=1000)\n\n# set shuffle to false since we already shuffle when the data is split into train/test\ntrain_loader = DataLoader(train_dataset, shuffle=False, batch_size=2 pin_memory=True)\nval_loader = DataLoader(val_dataset, shuffle=False, batch_size=2","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:30:14.512495Z","iopub.execute_input":"2023-07-29T20:30:14.513371Z","iopub.status.idle":"2023-07-29T20:30:14.533443Z","shell.execute_reply.started":"2023-07-29T20:30:14.513343Z","shell.execute_reply":"2023-07-29T20:30:14.532436Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[46], line 53\u001b[0;36m\u001b[0m\n\u001b[0;31m    train_loader = DataLoader(train_dataset, shuffle=False, batch_size=2 pin_memory=True)\u001b[0m\n\u001b[0m                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"],"ename":"SyntaxError","evalue":"invalid syntax. Perhaps you forgot a comma? (4114873204.py, line 53)","output_type":"error"}]},{"cell_type":"markdown","source":"#### Model Layers","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model, max_len):\n        \"\"\"\n        Inputs\n            d_model - Hidden dimensionality of the input.\n            max_len - Maximum length of a sequence to expect.\n        \"\"\"\n        super().__init__()\n\n        # Create matrix of [SeqLen, HiddenDim] representing the positional encoding for max_len inputs\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        # register_buffer => Tensor which is not a parameter, but should be part of the modules state.\n        # Used for tensors that need to be on the same device as the module.\n        # persistent=False tells PyTorch to not add the buffer to the state dict (e.g. when we save the model)\n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:12.166683Z","iopub.execute_input":"2023-07-29T20:51:12.167292Z","iopub.status.idle":"2023-07-29T20:51:12.177228Z","shell.execute_reply.started":"2023-07-29T20:51:12.167257Z","shell.execute_reply":"2023-07-29T20:51:12.176406Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"stft = TacotronSTFT(filter_length=1024, hop_length=256, win_length=1024, n_mel_channels=80, sampling_rate=22050, mel_fmin=0, mel_fmax=8000)\n#inv_mel_spec(mel_spec.T, 'file.wav', stft)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:12.178673Z","iopub.execute_input":"2023-07-29T20:51:12.179236Z","iopub.status.idle":"2023-07-29T20:51:13.060277Z","shell.execute_reply.started":"2023-07-29T20:51:12.179204Z","shell.execute_reply":"2023-07-29T20:51:13.058868Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout, hidden_dim, kernel_size):\n        super().__init__()\n        \n        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout, batch_first=True)\n        self.layer_norm = nn.LayerNorm(embed_dim)\n        self.dropout = nn.Dropout(dropout)\n        \n        self.mlp = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            Rearrange('B S E -> B E S'),\n            nn.Conv1d(embed_dim, hidden_dim, kernel_size, padding = (kernel_size - 1) // 2),\n            #nn.Linear(embed_dim, hidden_dim),\n            nn.GELU(),\n            nn.Dropout(dropout),\n            nn.Conv1d(hidden_dim, embed_dim, kernel_size, padding = (kernel_size - 1) // 2),\n            #nn.Linear(hidden_dim, embed_dim),\n            nn.Dropout(dropout),\n            Rearrange('B E S-> B S E')\n        )\n        \n        self._init_weights()\n        \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm1d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n        \n    def forward(self, x, mask=None, fill_mask=None):\n        x.masked_fill_(fill_mask, 0.0)\n        attn_in = self.layer_norm(x)\n        attn_out, _ = self.attention(attn_in, attn_in, attn_in, key_padding_mask=mask)\n        x_out = attn_out + x\n        \n        x_out.masked_fill_(fill_mask, 0.0)\n        mlp_out = self.mlp(x_out)\n        out = mlp_out + x_out\n        out.masked_fill_(fill_mask, 0.0)\n        return out\n    \n    \nclass TransformerEncoder(nn.Module):\n    def __init__(self, embed_dim, hidden_dim, num_heads, num_layers, kernel_size, max_src_seq_len, src_vocab_size, dropout=0.0):\n        super().__init__()\n        \n        self.pos_embedding = PositionalEncoding(embed_dim, max_src_seq_len)\n        self.phone_embedding = nn.Embedding(src_vocab_size, embed_dim, padding_idx=0)\n        self.layers = nn.Sequential(*[TransformerBlock(embed_dim, num_heads, dropout, hidden_dim, kernel_size)  for _ in range(num_layers)])\n        \n    def forward(self, x, mask=None, fill_mask=None):\n        x = self.phone_embedding(x)\n        x = self.pos_embedding(x)\n        \n        for l in self.layers:\n            x = l(x, mask, fill_mask)\n        \n        return x\n        \nclass TransformerDecoder(nn.Module):\n    def __init__(self, embed_dim, hidden_dim, num_heads, num_layers, kernel_size, max_trg_seq_len, dropout=0.0):\n        super().__init__()\n        \n        self.pos_embedding = PositionalEncoding(embed_dim, max_trg_seq_len)\n        self.layers = nn.Sequential(*[TransformerBlock(embed_dim, num_heads, dropout, hidden_dim, kernel_size)  for _ in range(num_layers)])\n        \n    def forward(self, x, mask=None, fill_mask=None):\n        x = self.pos_embedding(x)\n        \n        for l in self.layers:\n            x = l(x, mask, fill_mask)\n        \n        return x\n        \nclass Hidden2Mel(nn.Module):\n    def __init__(self, embed_dim, n_mels):\n        super().__init__()\n        self.layers = nn.Linear(embed_dim, n_mels)\n        \n    def forward(self, x):\n        return self.layers(x)\n    \nclass LengthRegulator(nn.Module):\n    def __init__(self, max_trg_len=1000):\n        super().__init__()\n\n        self.max_trg_len = max_trg_len\n\n    def forward(self, encoder_output, variance):\n        B = encoder_output.shape[0]\n        mels = list()\n\n        for b_idx in range(B):\n            expanded_seq = torch.concat([ encoder_output[b_idx,i,:].expand(v, -1) for i, v in enumerate(variance[b_idx, :]) ], dim=0)\n            seq_len = expanded_seq.shape[0]\n            pad_len = self.max_trg_len - seq_len\n\n            if pad_len < 0:\n                padded_seq = expanded_seq[:self.max_trg_len, :]\n            elif pad_len > 0:\n                padded_seq = F.pad( expanded_seq, (0, 0, 0, pad_len), \"constant\", -1 )\n\n            mels.append(padded_seq)\n        expanded_batch = torch.stack(mels, dim=0)\n        return expanded_batch\n    \nclass FastSpeechLoss(nn.Module):\n    def __init__(self, encoder_max_seq_len, decoder_max_seq_len):\n        super().__init__()\n\n        self.encoder_max_seq_len = encoder_max_seq_len\n        self.decoder_max_seq_len = decoder_max_seq_len\n        self.h2m_loss = nn.L1Loss()\n   \n    def forward(self,  h2m_pred_mels, trg_mels):\n        h2m_loss = self.h2m_loss(h2m_pred_mels, trg_mels)\n        return h2m_loss\n          \nclass FastSpeech(nn.Module):\n    def __init__(self, num_heads=2, num_layers=6, dropout=0.0, embed_dim=256, hidden_dim=512, kernel_size=3, max_trg_seq_len=1000, max_src_seq_len=200, src_vocab_size=360, n_mels=80):\n        super().__init__()\n        self.encoder_max_seq_len = max_src_seq_len\n        self.decoder_max_seq_len = max_trg_seq_len\n        self.embed_dim = embed_dim\n        self.n_mels = n_mels\n        \n        self.encoder = TransformerEncoder(num_heads=num_heads,\n                                          num_layers=num_layers,\n                                          dropout=dropout,\n                                          embed_dim=embed_dim,\n                                          hidden_dim=hidden_dim,\n                                          kernel_size=kernel_size,\n                                          src_vocab_size=src_vocab_size,\n                                          max_src_seq_len=max_src_seq_len)\n        \n        self.decoder = TransformerDecoder(num_heads=num_heads,\n                                          num_layers=num_layers,\n                                          dropout=dropout,\n                                          embed_dim=embed_dim,\n                                          hidden_dim=hidden_dim,\n                                          kernel_size=kernel_size,\n                                          max_trg_seq_len=max_trg_seq_len)\n        \n        self.hidden2mel = Hidden2Mel(n_mels=n_mels, embed_dim=embed_dim)\n        \n        self.length_regulator = LengthRegulator(max_trg_seq_len)\n        \n    def _get_masks(self, seq_lens, max_seq_len, embed_dim):\n        B = seq_lens.shape[0]\n        masks = [[ mask_idx >= seq_lens[seq_idx]  for mask_idx in torch.arange(max_seq_len)]  for seq_idx in torch.arange(0, B)]\n        masks = torch.tensor(masks)\n        fill_masks = repeat(masks.T, 'b s -> e b s', e=embed_dim).T.contiguous()\n        \n        return masks.to(device), fill_masks.to(device)\n        \n    def forward(self, src_seq, src_seq_len, trg_seq, trg_seq_len, trg_durations):\n        src_masks, src_fill_masks = self._get_masks(src_seq_len, self.encoder_max_seq_len, self.embed_dim)\n        trg_masks, trg_fill_masks = self._get_masks(trg_seq_len, self.decoder_max_seq_len, self.embed_dim)\n        _, mel_fill_masks = self._get_masks(trg_seq_len, self.decoder_max_seq_len, self.n_mels)\n        \n        enc_out = self.encoder(src_seq, src_masks, src_fill_masks)\n        adapted_enc_out = self.length_regulator(enc_out, trg_durations)\n        dec_out = self.decoder(adapted_enc_out, trg_masks, trg_fill_masks)\n        out = self.hidden2mel(dec_out).masked_fill(mel_fill_masks, 0.0)\n        \n        return out\n    \n\n# model = FastSpeech(\n#     num_heads=2,\n#     num_layers=6,\n#     dropout=0.0, \n#     embed_dim=256,\n#     hidden_dim=512,\n#     kernel_size=3,\n#     max_trg_seq_len=1000,\n#     max_src_seq_len=200,\n#     n_mels=80,\n#     src_vocab_size=len(_symbol_to_id)\n# )\n\n# phonemes, phoneme_lens, mels, mel_lens, durations = next(iter(train_loader))\n\n# o = model(phonemes, phoneme_lens, mels, mel_lens, durations)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:13.067685Z","iopub.execute_input":"2023-07-29T20:51:13.068683Z","iopub.status.idle":"2023-07-29T20:51:13.144408Z","shell.execute_reply.started":"2023-07-29T20:51:13.068647Z","shell.execute_reply":"2023-07-29T20:51:13.142849Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class FastSpeechModule(pl.LightningModule):\n    def __init__(self, **kwargs):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = FastSpeech(\n                        num_heads=2,\n                        num_layers=6,\n                        dropout=0.0, \n                        embed_dim=256,\n                        hidden_dim=512,\n                        kernel_size=3,\n                        max_trg_seq_len=1000,\n                        max_src_seq_len=200,\n                        n_mels=80,\n                        src_vocab_size=len(_symbol_to_id)\n                    )\n        \n        self.loss_module = FastSpeechLoss(encoder_max_seq_len=200, decoder_max_seq_len=1000)\n        \n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n        return [optimizer], [lr_scheduler]\n    \n    def training_step(self, batch, batch_idx):\n        phonemes, phoneme_lens, mels, mel_lens, durations = batch\n        preds = self.model(phonemes, phoneme_lens, mels, mel_lens, durations)\n        loss = self.loss_module(preds, mels)\n        self.log(f'train_loss', loss, on_step=True, on_epoch=True)\n        \n        if self.current_epoch in [1, 60, 120, 198]:\n            inv_mel_spec(preds[0].T, f'file_{self.current_epoch}.wav', stft)\n            print('synth')\n        \n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        phonemes, phoneme_lens, mels, mel_lens, durations = batch\n        preds = self.model(phonemes, phoneme_lens, mels, mel_lens, durations)\n        loss = self.loss_module(preds, mels)\n        self.log(f'val_loss', loss, on_epoch=True)\n    \n    def test_step(self, batch, batch_idx):\n        phonemes, phoneme_lens, mels, mel_lens, durations = batch\n        preds = self.model(phonemes, phoneme_lens, mels, mel_lens, durations)\n        loss = self.loss_module(preds, mels)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:13.148308Z","iopub.execute_input":"2023-07-29T20:51:13.149141Z","iopub.status.idle":"2023-07-29T20:51:13.170783Z","shell.execute_reply.started":"2023-07-29T20:51:13.149106Z","shell.execute_reply":"2023-07-29T20:51:13.169548Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.finish()\nwandb_logger = WandbLogger(project='Fast Speech 2 - Improved', name='spanish cha cha cha 2')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:13.172782Z","iopub.execute_input":"2023-07-29T20:51:13.173701Z","iopub.status.idle":"2023-07-29T20:51:48.048789Z","shell.execute_reply.started":"2023-07-29T20:51:13.173661Z","shell.execute_reply":"2023-07-29T20:51:48.047938Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msitholedavid003\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>./wandb/run-20230729_205116-zukkzrl3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/zukkzrl3' target=\"_blank\">spanish cha cha cha 2</a></strong> to <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved' target=\"_blank\">https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/zukkzrl3' target=\"_blank\">https://wandb.ai/sitholedavid003/Fast%20Speech%202%20-%20Improved/runs/zukkzrl3</a>"},"metadata":{}}]},{"cell_type":"code","source":"def train_model(**kwargs):\n    trainer = pl.Trainer(default_root_dir=os.path.join('checkpoints', 'initial model x'),\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=200,\n                         logger=wandb_logger,\n                         overfit_batches=1,\n                         callbacks=[\n                             ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_loss\"),\n                                    LearningRateMonitor(\"epoch\")]\n                        )\n    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    pl.seed_everything(42) # To be reproducable\n    model = FastSpeechModule(**kwargs)\n    trainer.fit(model, train_loader, val_loader)\n    model = FastSpeechModule.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n\n    # Test best model on validation and test set\n    val_result = trainer.test(model, val_loader, verbose=False)\n    result = {\"val\": val_result[0][\"test_loss\"]}\n    return model, result\n\nmodel, results = train_model(lr=3e-4)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T20:51:48.052987Z","iopub.execute_input":"2023-07-29T20:51:48.055455Z","iopub.status.idle":"2023-07-29T20:55:44.954097Z","shell.execute_reply.started":"2023-07-29T20:51:48.055421Z","shell.execute_reply":"2023-07-29T20:55:44.951324Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_29/2331699849.py:154: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3571.)\n  fill_masks = repeat(masks.T, 'b s -> e b s', e=embed_dim).T.contiguous()\n/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:1144: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/transformers/attention.cpp:150.)\n  return torch._native_multi_head_attention(\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  rank_zero_warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8833568d87bf485184aa7b2c39f3a356"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"synth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c8ecffbc4fc40b68d984d46cab7b5ae"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, result\n\u001b[0;32m---> 26\u001b[0m model, results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Test best model on validation and test set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m val_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(model, val_loader, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mval_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m}\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, result\n","\u001b[0;31mKeyError\u001b[0m: 'test_loss'"],"ename":"KeyError","evalue":"'test_loss'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ViT Stuff","metadata":{}},{"cell_type":"code","source":"class VisionTransformer(nn.Module):\n    def __init__(self, embed_dim, hidden_dim, num_channels, num_heads, num_layers, num_classes, patch_size, num_patches, kernel_size, dropout=0.0):\n        super().__init__()\n        \n        input_dim = patch_size * patch_size * num_channels\n        \n        self.input_net = nn.Sequential(\n            Rearrange('B C (h p1) (w p2) -> B (h w) (C p1 p2)', p1=patch_size, p2=patch_size),\n            nn.Linear(input_dim, embed_dim)\n        )\n        \n        self.positional_embedding = nn.Embedding(num_patches + 1, embed_dim) # +1 for the CLS token\n        \n        self.mlp = nn.Sequential(\n            nn.LayerNorm(embed_dim),\n            nn.Linear(embed_dim, num_classes),\n        )\n        \n        self.encoder = nn.Sequential(*[\n            TransformerBlock(embed_dim, num_heads, dropout, hidden_dim, kernel_size) for _ in range(num_layers)\n        ])\n        \n        self.dropout = nn.Dropout(dropout)\n        \n        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n        \n    def forward(self, x):\n        x = self.input_net(x)\n        B, T, _ = x.shape\n        cls_token = repeat(self.cls_token, '1 1 N -> B 1 N', B=B)\n        x = torch.cat([cls_token, x], dim=1)\n        pos = torch.arange(0, T+1).to(device)\n        x = x + self.positional_embedding(pos)\n        x = self.dropout(x)\n        x = self.encoder(x)\n        out = self.mlp(x[:, 0, :])\n        return out\n    \nt = VisionTransformer(**{ 'embed_dim': 256,\n                                'hidden_dim': 512,\n                                'num_heads': 8,\n                                'num_layers': 6,\n                                'patch_size': 4,\n                                'num_channels': 3,\n                                'num_patches': 64,\n                                'num_classes': 10,\n                                'dropout': 0.2,\n                                'kernel_size': 3\n                        })\n\n# t(torch.randn(6, 3, 32, 32)).shape\n\nclass ViT(pl.LightningModule):\n\n    def __init__(self, model_kwargs, lr):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = VisionTransformer(**model_kwargs)\n        self.example_input_array = next(iter(train_loader))[0]\n\n    def forward(self, x):\n        return self.model(x)\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n        return [optimizer], [lr_scheduler]\n\n    def _calculate_loss(self, batch, mode=\"train\"):\n        imgs, labels = batch\n        preds = self.model(imgs)\n        loss = F.cross_entropy(preds, labels)\n        acc = (preds.argmax(dim=-1) == labels).float().mean()\n\n        self.log(f'{mode}_loss', loss, on_step=True, on_epoch=True)\n        self.log(f'{mode}_acc', acc, on_step=True, on_epoch=True)\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        loss = self._calculate_loss(batch, mode=\"train\")\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        self._calculate_loss(batch, mode=\"val\")\n\n    def test_step(self, batch, batch_idx):\n        self._calculate_loss(batch, mode=\"test\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()\nwandb_logger = WandbLogger(project='FastSpeech2', name='ViT CNN v2')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(**kwargs):\n    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"ViT CNN\"),\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=180,\n                         logger=wandb_logger,\n                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n                                    LearningRateMonitor(\"epoch\")])\n    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    pl.seed_everything(42) # To be reproducable\n    model = ViT(**kwargs)\n    trainer.fit(model, train_loader, val_loader)\n    model = ViT.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n\n    # Test best model on validation and test set\n    val_result = trainer.test(model, val_loader, verbose=False)\n    test_result = trainer.test(model, test_loader, verbose=False)\n    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n    return model, result\n\nmodel, results = train_model(model_kwargs={\n                                'embed_dim': 256,\n                                'hidden_dim': 512,\n                                'num_heads': 8,\n                                'num_layers': 6,\n                                'patch_size': 4,\n                                'num_channels': 3,\n                                'num_patches': 64,\n                                'num_classes': 10,\n                                'dropout': 0.2,\n                                'kernel_size': 3\n                            },\n                            lr=3e-4)\n\nprint(\"ViT results\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}